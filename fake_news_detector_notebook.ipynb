{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9w18zyADs9oI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CTykU8BtZiG"
      },
      "source": [
        "Install libraries that we are going to use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12jIgEbNtXoI"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers huggingface_hub evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oC5elX-UtnQO"
      },
      "source": [
        "To use git in this model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75nL7p7itf0z"
      },
      "outputs": [],
      "source": [
        "!apt-get install git-lfs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D2V_abSuCYV"
      },
      "source": [
        "# Upload the kaggle dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acHH_I6evkqV"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()  # This will prompt you to upload the kaggle.json file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Csrst5AMvs5R"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnD7Wrqjv1ph"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d emineyetm/fake-news-detection-datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEGxYagGv6zq"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Unzip the dataset\n",
        "with zipfile.ZipFile(\"fake-news-detection-datasets.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"fake-news-detection-datasets\")\n",
        "\n",
        "# Verify the files\n",
        "print(os.listdir(\"fake-news-detection-datasets\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the function to remove stopwords"
      ],
      "metadata": {
        "id": "R-MqHR8erzQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Define stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def remove_stopwords(example):\n",
        "    example['text'] = ' '.join([word for word in example['text'].split() if word.lower() not in stop_words])\n",
        "    return example"
      ],
      "metadata": {
        "id": "bYXL5wE3uUa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge 3 different datasets to measure generalablity of the model best and remove the stopwords from them"
      ],
      "metadata": {
        "id": "vOxMfTVAEM5O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60tWyCeAwECn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example: Load a CSV file\n",
        "fakes = pd.read_csv(\"/content/fake-news-detection-datasets/News _dataset/Fake.csv\")\n",
        "trues = pd.read_csv(\"/content/fake-news-detection-datasets/News _dataset/True.csv\")\n",
        "\n",
        "# Add a label part both\n",
        "fakes[\"label\"] = 0\n",
        "trues[\"label\"] = 1\n",
        "\n",
        "# merge these sets\n",
        "merged_df = pd.concat([fakes, trues], ignore_index=True)\n",
        "# remove subject and date columns\n",
        "merged_df = merged_df.drop([\"subject\", \"date\"], axis=1)\n",
        "# merge title and text columns with :\n",
        "merged_df[\"text\"] = merged_df[\"title\"] + \" : \" + merged_df[\"text\"]\n",
        "# remove title column\n",
        "merged_df = merged_df.drop([\"title\"], axis=1)\n",
        "# shuffle data\n",
        "merged_df = merged_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "pol_dataset = Dataset.from_pandas(merged_df)\n",
        "pol_dataset = pol_dataset.select(range(10000))\n",
        "print(pol_dataset.column_names)  # Check column names in the split\n",
        "\n",
        "# Another dataset----------------------------------------------------------------------------------------------------\n",
        "ds = load_dataset(\"noahgift/fake-news\")\n",
        "print(ds.column_names)  # Check column names in the split\n",
        "ds1 = ds[\"train\"]\n",
        "ds1 = ds1.select_columns([\"text\", \"label\"])\n",
        "ds1 = ds1.select(range(2000))\n",
        "# Define a mapping from string labels to integers\n",
        "label_mapping2 = {\"Real\": 1, \"Fake\": 0}\n",
        "ds1 = ds1.map(lambda example: {\"label\": label_mapping2[example[\"label\"]]})\n",
        "print(ds1.column_names)  # Check column names in the split\n",
        "\n",
        "# Last dataset----------------------------------------------------------------------------------------------------\n",
        "dataset = load_dataset(\"Cartinoe5930/Politifact_fake_news\")\n",
        "dataset1 = dataset[\"train\"]\n",
        "# cahgen the column anme news to text\n",
        "dataset1 = dataset1.rename_column(\"news\", \"text\")\n",
        "dataset1 = dataset1.select_columns([\"text\", \"label\"])\n",
        "dataset1 = dataset1.select(range(10000))\n",
        "print(dataset1.column_names)  # Check column names in the split\n",
        "\n",
        "\n",
        "\n",
        "# merge pol_dataset, dataset1, and ds1\n",
        "merged_df = pd.concat([pol_dataset.to_pandas(), dataset1.to_pandas(), ds1.to_pandas()], ignore_index=True)\n",
        "\n",
        "# shuffle\n",
        "merged_df = merged_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "#convert to dataset\n",
        "merged_df = Dataset.from_pandas(merged_df)\n",
        "print(merged_df.column_names)  # Check column names in the split\n",
        "print(merged_df[0])\n",
        "merged_df = merged_df.map(remove_stopwords)\n",
        "print(merged_df[0])\n",
        "\n",
        "\n",
        "#split to train and test\n",
        "dataset_split = merged_df.train_test_split(test_size=0.2, seed=42)\n",
        "train_df = dataset_split[\"train\"]\n",
        "test_df = dataset_split[\"test\"]\n",
        "#check\n",
        "print(train_df.column_names)  # Check column names in the split\n",
        "print(test_df.column_names)  # Check column names in the spli\n",
        "print(train_df.shape)\n",
        "print(test_df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2JvCI6V2eyK"
      },
      "source": [
        "# Load the tokenizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYyW9GGR2ibB"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDr0A_lk3M4W"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4TIg6Vk2p1-"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "   return tokenizer(examples[\"text\"], truncation=True)\n",
        "\n",
        "# Now you can map with batched=True\n",
        "tokenized_train = train_df.map(preprocess_function, batched=True)\n",
        "tokenized_test = test_df.map(preprocess_function, batched=True)\n",
        "\n",
        "# Show the shape of the datas\n",
        "print(tokenized_train.shape)\n",
        "print(tokenized_test.shape)\n",
        "\n",
        "#Show the first 5 elements of the datasets\n",
        "print(tokenized_train[:5])\n",
        "print(tokenized_test[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEQLgWka3_eK"
      },
      "source": [
        "**Use data_collator to speed up training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8xXNHAG389l"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\# Upload the distilBERT model to fine-tune"
      ],
      "metadata": {
        "id": "Pdp9wp_2Eg-9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvuS9ThqtzZs"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Metrices**"
      ],
      "metadata": {
        "id": "YvM6m2LE9bP0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNP70nFGtzWT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"binary\")\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdCDW7U44MJT"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COMMAND 1"
      ],
      "metadata": {
        "id": "cCf9Tb9W3Qza"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train the distilBERT model with created dataset and evaluate it. This is our baseline.**"
      ],
      "metadata": {
        "id": "C4k2SUh99Rmh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7T5vqdN4V1d"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "repo_name = \"fake-news-model-22000-samples\"\n",
        "\n",
        "dataset_split = tokenized_train.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "# Extract training and validation datasets\n",
        "train_dataset = dataset_split[\"train\"]\n",
        "eval_dataset = dataset_split[\"test\"]\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "   output_dir=repo_name,\n",
        "   learning_rate=2e-5,\n",
        "   per_device_train_batch_size=16,\n",
        "   per_device_eval_batch_size=16,\n",
        "   num_train_epochs=10,\n",
        "   weight_decay=0.01,\n",
        "   save_strategy=\"epoch\",\n",
        "   eval_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
        "   logging_dir=f\"{repo_name}/logs\",  # Directory for logs\n",
        "   logging_strategy=\"epoch\",  # Log metrics at the end of each epoch\n",
        "   push_to_hub=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "   model=model,\n",
        "   args=training_args,\n",
        "   train_dataset=train_dataset,\n",
        "   eval_dataset=eval_dataset,\n",
        "   processing_class=tokenizer,\n",
        "   data_collator=data_collator,\n",
        "   compute_metrics=compute_metrics,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXXmmQm_4_B8"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Push to hub to use again."
      ],
      "metadata": {
        "id": "-QYxioKv9Ku0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-0IBc3i8ygE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "2e3b481b9473457186ae84f5151df960",
            "6d3abfb9fb8748f29b79c0e92f607792",
            "7dc08b4e6b244ebebc20f811151d5d01",
            "d45c7866a5e742ee9f358264614d4d17",
            "4b4040f7dae2496696c20c0396501d3f",
            "f99c519b67654d168252f72383b4b4d8",
            "2aafc3d27af2475a84d31bef7db924d0",
            "eaa38621c76d434baf6e02d24e75d908",
            "ba312ef87a8a42d29b09f2f77d22a349",
            "b394477b2ebc47f8865b4e8d0e17be07",
            "d08ddb58e2984f1facb1a63ea3643fc6"
          ]
        },
        "outputId": "5e516641-6e8d-4078-9393-470ffa9db75a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "events.out.tfevents.1735040137.4e57bcf02596.557.0:   0%|          | 0.00/12.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e3b481b9473457186ae84f5151df960"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/ilhamiuturkkan/fake-news-model-22000-samples/commit/0882a7c0536d45d54aff9429af40ccb3f974f030', commit_message='End of training', commit_description='', oid='0882a7c0536d45d54aff9429af40ccb3f974f030', pr_url=None, repo_url=RepoUrl('https://huggingface.co/ilhamiuturkkan/fake-news-model-22000-samples', endpoint='https://huggingface.co', repo_type='model', repo_id='ilhamiuturkkan/fake-news-model-22000-samples'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the trained model\n"
      ],
      "metadata": {
        "id": "zKxUQpj28wCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "fake_news_model = pipeline(model=\"ilhamiuturkkan/fake-news-model-22000-samples\", device=0)"
      ],
      "metadata": {
        "id": "9L1cT4eN8zxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Since distilBERT has max 512 token capacity. Tokenize the input with respect to it."
      ],
      "metadata": {
        "id": "q_cj5MA286M1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def truncate_texts_to_max_length(texts, tokenizer, max_length=512):\n",
        "    return [\n",
        "        tokenizer.decode(\n",
        "            tokenizer(\n",
        "                text,\n",
        "                max_length=max_length,\n",
        "                truncation=True,  # Ensure truncation\n",
        "            )[\"input_ids\"],\n",
        "            skip_special_tokens=True,\n",
        "        )\n",
        "        for text in texts\n",
        "    ]"
      ],
      "metadata": {
        "id": "7RdfNsyY9C9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the trained distilBERT model"
      ],
      "metadata": {
        "id": "Kc5SWHITE4G_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBBJK5LJ85oQ"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Truncate texts to the model's maximum token length\n",
        "test_texts = truncate_texts_to_max_length(tokenized_test[\"text\"], tokenizer)\n",
        "test_labels = tokenized_test[\"label\"]\n",
        "\n",
        "outputs = fake_news_model(test_texts)\n",
        "\n",
        "# Define a mapping from string labels to integers\n",
        "label_mapping = {\"LABEL_0\": 0, \"LABEL_1\": 1}\n",
        "\n",
        "# Convert predictions to integers by accessing the \"label\" key\n",
        "predictions = [label_mapping[output[\"label\"]] for output in outputs]\n",
        "ground_truths = test_labels\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(ground_truths, predictions)\n",
        "print(f\"Accuracy with trained model: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COMMAND 2"
      ],
      "metadata": {
        "id": "4Serl46L3ZW-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now, work for LSTM"
      ],
      "metadata": {
        "id": "z9nevVKm-tlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts = tokenizer(train_dataset[\"text\"], return_tensors=\"pt\", padding='max_length', truncation=True, max_length=256)\n",
        "train_labels = train_dataset[\"label\"]\n",
        "val_texts = tokenizer(eval_dataset[\"text\"], return_tensors=\"pt\", padding='max_length', truncation=True, max_length=256)\n",
        "val_labels = eval_dataset[\"label\"]\n",
        "test_texts = tokenizer(tokenized_test[\"text\"], return_tensors=\"pt\", padding='max_length', truncation=True, max_length=256)\n",
        "test_labels = tokenized_test[\"label\"]"
      ],
      "metadata": {
        "id": "Ljm-RE2x-tFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First get the embeddings of the train set texts**"
      ],
      "metadata": {
        "id": "Ms9w1nmJEFcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "labels_tensor = torch.tensor(train_labels)\n",
        "dataset = TensorDataset(train_texts.input_ids, train_texts.attention_mask, labels_tensor)\n",
        "loader = DataLoader(dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "iARKZlEP_PAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "model = DistilBertModel.from_pretrained('distilbert-base-uncased', num_labels=2)"
      ],
      "metadata": {
        "id": "RDshnYWhL6th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "embeddings = []\n",
        "for batch in loader:\n",
        "    # Move inputs to the same device as the model\n",
        "    batch_input_ids, batch_attention_mask = batch[0].to(device), batch[1].to(device)\n",
        "    with torch.no_grad():\n",
        "        # Get the embeddings from the model\n",
        "        outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n",
        "        batch_embeddings = outputs.last_hidden_state.cpu().numpy()  # Move embeddings to CPU for storage\n",
        "        embeddings.append(batch_embeddings)\n"
      ],
      "metadata": {
        "id": "jCSnUzlmBkC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_embeddings = np.concatenate(embeddings, axis=0)\n",
        "#Random embedding to verify\n",
        "print(train_embeddings[12])"
      ],
      "metadata": {
        "id": "0gdOk7FsDlV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now, get the embeddings of evaluation set**"
      ],
      "metadata": {
        "id": "13HueMijD9pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_tensor = torch.tensor(val_labels)\n",
        "dataset = TensorDataset(val_texts.input_ids, val_texts.attention_mask, labels_tensor)\n",
        "loader = DataLoader(dataset, batch_size=32)\n",
        "model = model.to(device=0)\n",
        "\n",
        "embeddings = []\n",
        "for batch in loader:\n",
        "    # Move inputs to the same device as the model\n",
        "    batch_input_ids, batch_attention_mask = batch[0].to(device), batch[1].to(device)\n",
        "    with torch.no_grad():\n",
        "        # Get the embeddings from the model\n",
        "        outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n",
        "        batch_embeddings = outputs.last_hidden_state.cpu().numpy()  # Move embeddings to CPU for storage\n",
        "        embeddings.append(batch_embeddings)"
      ],
      "metadata": {
        "id": "OK8162RbD4TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_embeddings = np.concatenate(embeddings, axis=0)"
      ],
      "metadata": {
        "id": "4qCzLex8E8XZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now, define the LSTM Biderctional Model and train it with obtained embeddings."
      ],
      "metadata": {
        "id": "hZO7NQ6cFH0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from transformers import Trainer, AutoTokenizer, AdamW, TrainingArguments\n",
        "\n",
        "dropout_rate = 0.2\n",
        "l2_strength=0.005\n",
        "print((train_embeddings.shape[1], train_embeddings.shape[2]))\n",
        "bidirectional_model = tf.keras.Sequential([\n",
        "    tf.keras.Input(shape=(train_embeddings.shape[1], train_embeddings.shape[2])),\n",
        "    #tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(l2_strength)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True, dropout=dropout_rate, recurrent_dropout=dropout_rate, kernel_regularizer=l2(l2_strength))),\n",
        "    tf.keras.layers.GlobalMaxPooling1D(),\n",
        "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=l2(l2_strength)),\n",
        "    tf.keras.layers.Dropout(dropout_rate),\n",
        "    tf.keras.layers.Dense(2, activation='softmax', kernel_regularizer=l2(l2_strength))])\n"
      ],
      "metadata": {
        "id": "Mm83zpLGFPE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "bidirectional_model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),  # Lower learning rate for finer updates\n",
        "    loss=CategoricalCrossentropy(label_smoothing=0.1),  # Label smoothing for better generalization\n",
        "    metrics=[\n",
        "        'accuracy',\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall'),\n",
        "        tf.keras.metrics.F1Score(name='f1_score')\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "AFs8qEd0FnpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "train_y_one_hot = to_categorical(train_labels, num_classes=2)\n",
        "val_y_one_hot = to_categorical(val_labels, num_classes=2)"
      ],
      "metadata": {
        "id": "qeaOGs1JFrzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the shapes.\n",
        "print(train_embeddings.shape)\n",
        "print(val_embeddings.shape)\n",
        "print(np.array(train_y_one_hot).shape)\n",
        "print(np.array(val_y_one_hot).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LfTd54PF1U1",
        "outputId": "292b6998-dff5-4fcf-8d06-792a55f60e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14080, 256, 768)\n",
            "(3520, 256, 768)\n",
            "(14080, 2)\n",
            "(3520, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 64\n",
        "num_epochs = 10\n",
        "\n",
        "train_history = bidirectional_model.fit(train_embeddings,\n",
        "                                          np.array(train_y_one_hot),\n",
        "                                          batch_size=batch_size,\n",
        "                                          epochs=num_epochs,\n",
        "                                          validation_data=(val_embeddings, np.array(val_y_one_hot)))\n",
        "\n",
        "# Extract metrics\n",
        "train_accuracy = train_history.history['accuracy']\n",
        "val_accuracy = train_history.history['val_accuracy']\n",
        "epochs = range(1, len(train_accuracy) + 1)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Train Accuracy\n",
        "plt.plot(epochs, train_accuracy, marker='o', linestyle='-', label=\"Train Accuracy\")\n",
        "\n",
        "# Validation Accuracy\n",
        "plt.plot(epochs, val_accuracy, marker='o', linestyle='-', label=\"Validation Accuracy\", color=\"orange\")\n",
        "\n",
        "# Title and Labels\n",
        "plt.title(\"Training and Validation Accuracy per Epoch\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xticks(epochs)\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rM3UWWleF6r_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_tensor = torch.tensor(test_labels)\n",
        "dataset = TensorDataset(test_texts.input_ids, test_texts.attention_mask, labels_tensor)\n",
        "loader = DataLoader(dataset, batch_size=32)\n",
        "\n",
        "model = model.to(device=0)\n",
        "\n",
        "embeddings = []\n",
        "for batch in loader:\n",
        "    # Move inputs to the same device as the model\n",
        "    batch_input_ids, batch_attention_mask = batch[0].to(device), batch[1].to(device)\n",
        "    with torch.no_grad():\n",
        "        # Get the embeddings from the model\n",
        "        outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n",
        "        batch_embeddings = outputs.last_hidden_state.cpu().numpy()  # Move embeddings to CPU for storage\n",
        "        embeddings.append(batch_embeddings)\n",
        "test_embeddings = np.concatenate(embeddings, axis=0)\n",
        "\n",
        "test_y_one_hot = to_categorical(test_labels, num_classes=2)\n",
        "\n",
        "test_history = bidirectional_model.evaluate(test_embeddings, np.array(test_y_one_hot))"
      ],
      "metadata": {
        "id": "s3sPRkdMI4gY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bidirectional_model.summary()"
      ],
      "metadata": {
        "id": "1ZiP5NYqkOuq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2e3b481b9473457186ae84f5151df960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d3abfb9fb8748f29b79c0e92f607792",
              "IPY_MODEL_7dc08b4e6b244ebebc20f811151d5d01",
              "IPY_MODEL_d45c7866a5e742ee9f358264614d4d17"
            ],
            "layout": "IPY_MODEL_4b4040f7dae2496696c20c0396501d3f"
          }
        },
        "6d3abfb9fb8748f29b79c0e92f607792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f99c519b67654d168252f72383b4b4d8",
            "placeholder": "​",
            "style": "IPY_MODEL_2aafc3d27af2475a84d31bef7db924d0",
            "value": "events.out.tfevents.1735040137.4e57bcf02596.557.0: 100%"
          }
        },
        "7dc08b4e6b244ebebc20f811151d5d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaa38621c76d434baf6e02d24e75d908",
            "max": 12130,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba312ef87a8a42d29b09f2f77d22a349",
            "value": 12130
          }
        },
        "d45c7866a5e742ee9f358264614d4d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b394477b2ebc47f8865b4e8d0e17be07",
            "placeholder": "​",
            "style": "IPY_MODEL_d08ddb58e2984f1facb1a63ea3643fc6",
            "value": " 12.1k/12.1k [00:00&lt;00:00, 36.4kB/s]"
          }
        },
        "4b4040f7dae2496696c20c0396501d3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f99c519b67654d168252f72383b4b4d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aafc3d27af2475a84d31bef7db924d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eaa38621c76d434baf6e02d24e75d908": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba312ef87a8a42d29b09f2f77d22a349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b394477b2ebc47f8865b4e8d0e17be07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d08ddb58e2984f1facb1a63ea3643fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}